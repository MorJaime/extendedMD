{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMD algorithm - quick and dirty implementation\n",
    "\n",
    "## Maria InÃªs Silva\n",
    "## 10/01/2019\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo-code from the paper\n",
    "\n",
    "The efficient EMD paper uses the following parameter setting:\n",
    "* Tmin - the minimum length of analysis window (in data points).\n",
    "* a - the SAX alphabet size.\n",
    "* w - the number of SAX symbols in one BS.\n",
    "* aw - the size of the analysis window, which is measured in the number of BSs.\n",
    "\n",
    "### Algorithm EMD\n",
    "\n",
    "1. Transform the original time series to PAA representation, using a slideing window of size `T_min`.\n",
    "2. Transform the PAA reduced time series to SAX symbol sequence.\n",
    "3. Transform the SAX symbol sequence to BS sequence.\n",
    "4. Transform the BS sequence to Modified BS sequence.\n",
    "5. Find all the motif candidates:\n",
    "    1. Set the size of analysis window, W, to `T_min`.\n",
    "    2. Extract all modified BS subsequences under the analysis window, by sliding the window from left to right. Find some DL pattern from these subsequences, if any. If there exists no DL pattern found and the window is now at the end of the Modified BS sequence, go to step 6.\n",
    "    3. From the set of all pattern instances found in 5.B, establish the distance matrix for them (using DTW distance to calculate the distances between them). Call the procedure `Extract_Motif_Candidate` to find the motif candidate from the distance matrix, and calculate the MDL value of the candidate.\n",
    "    4. Add the motif candidate to the result list along with its MDL value.\n",
    "    5. Increase the size of the analysis window (i.e., Set W: = W + 1), go to 5.2\n",
    "6. From the result list, find the motif candidate with the smallest MDL value. The found motif will be the returned result\n",
    "\n",
    "### Algorithm `Extract_Motif_Candidate`\n",
    "\n",
    "1. For each TSS in the distance matrix, identify all the other TSS which are similar to it (i.e., the distance between them is less than the threshold R).\n",
    "2. Select as the pattern instances the TSSs which have the highest count of its similar subsequence.\n",
    "3. Among the pattern instances selected in step 2, determine the instance which has the smallest sum of distances to all the other instances. This one is considered as the centre of the pattern (that means a motif candidate).\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "from dtaidistance import dtw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/maria.silva/Documents/Tese/extendedMD/data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "data_folder = os.path.abspath(os.path.join(cwd, os.pardir, 'data'))\n",
    "data_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ay</th>\n",
       "      <th>az</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>-0.027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ay     az\n",
       "0 -0.034  0.013\n",
       "1 -0.005  0.003\n",
       "2  0.006  0.010\n",
       "3  0.004 -0.012\n",
       "4 -0.012 -0.027"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ay = pd.read_csv(os.path.join(data_folder, 'ay.csv'), names=['ay'])\n",
    "az = pd.read_csv(os.path.join(data_folder, 'az.csv'), names=['az'])\n",
    "\n",
    "data = ay.assign(az = az['az'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ay'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PCA\n",
    "\n",
    "**input:** data (pandas dataframe where each column is a timeseries.Number of columns is the number of variable to apply pca)\n",
    "\n",
    "**output:** numpy array that represents the 1-dimensional time series resulting from the PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pca_ts(multi_dim_ts):\n",
    "    # compute vector with the mean of each time series\n",
    "    means_vec = data.agg('mean').values\n",
    "    # compute the covariance matrix of the multi-dim time-series data\n",
    "    cov_mat = multi_dim_ts.cov().values\n",
    "    # extract eigenvalues and eigenvectors (the PCs) of the covariance matrix\n",
    "    e_val, e_vec = np.linalg.eigh(cov_mat)\n",
    "    # get the eigenvector with the highest eigenvalue (i.e. the 1st PC)\n",
    "    pc1_vec = e_vec[np.argmax(e_val)]\n",
    "    # compute the 1-dim time series as the data's projection on the 1st PC\n",
    "    ts_1d = np.dot((multi_dim_ts.values - means_vec), pc1_vec)\n",
    "    return ts_1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_1d = extract_pca_ts(data)\n",
    "ts_1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SAX\n",
    "\n",
    "Code based on the function `sax_via_window` from `saxpy.sax`.\n",
    "\n",
    "**input:** 1-d time series, sliding window size, PAA representation size, alphabet size and z-normalization threshold (??)\n",
    "\n",
    "**output:** list of sax words (one word per sliding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from saxpy.znorm import znorm\n",
    "from saxpy.paa import paa\n",
    "from saxpy.alphabet import cuts_for_asize\n",
    "from saxpy.sax import ts_to_string\n",
    "\n",
    "def extract_sax_sequence(ts, win_size, paa_size, alphabet_size=3, z_threshold=0.01):\n",
    "    # initialize list with sax sequence\n",
    "    sax_sequence = []\n",
    "    # get the cuts thresholds based on the gaussian distribution\n",
    "    cuts = cuts_for_asize(alphabet_size)\n",
    "    for t in range(0, len(ts) - win_size + 1):\n",
    "        # define the current window\n",
    "        ts_win = ts[t:(t+win_size)]\n",
    "        # normalize the window\n",
    "        ts_win_normalized = znorm(ts_win, z_threshold)\n",
    "        # compute PAA representation of normalized window\n",
    "        paa_rep = paa(ts_win_normalized, paa_size)\n",
    "        # compute sax representation of PAA representation\n",
    "        sax_word = ts_to_string(paa_rep, cuts)\n",
    "        # append sax word to sax sequence list\n",
    "        sax_sequence.append(sax_word)\n",
    "    return sax_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "win_size=9\n",
    "paa_size=3\n",
    "alphabet_size=3\n",
    "\n",
    "sax_sequence = extract_sax_sequence(ts_1d, win_size, paa_size, alphabet_size)\n",
    "np.unique(sax_sequence, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract modified BS-sequence\n",
    "\n",
    "**input:** sax sequence\n",
    "\n",
    "**output:** a list with the modified bs sequence and a list with the lenght of each bs in the sequence (if there were two sax words together, then the lenght of the result bs sequence is 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_modified_bs_sequence(sax_sequence):\n",
    "    # initialize the lists to save the bs and their lenghts\n",
    "    bs_seq = []\n",
    "    bs_len = []\n",
    "    # initialize the bs lenght counter\n",
    "    curr_len = 1\n",
    "    for i in range(len(sax_sequence)):\n",
    "        # set the current bs element\n",
    "        curr_bs = sax_sequence[i]\n",
    "        # set the next bs element\n",
    "        if i<len(sax_sequence)-1:\n",
    "            next_bs = sax_sequence[i+1]\n",
    "        else: # if the current element is the last, then thre's no \"next_bs\"\n",
    "            next_bs = ''\n",
    "        # test if the current bs is equal to the next bs\n",
    "        if curr_bs==next_bs:\n",
    "            # if yes, add 1 to the current lenght counter\n",
    "            curr_len = curr_len + 1\n",
    "        else:\n",
    "            # if no, save the bs and its lenght in the corresponding lists\n",
    "            bs_seq.append(curr_bs)\n",
    "            bs_len.append(curr_len)\n",
    "            # and initialize the lenght counter\n",
    "            curr_len = 1\n",
    "    return bs_seq, bs_len\n",
    "\n",
    "def generate_bs_pointers(bs_len, bs_size):\n",
    "    bs_pointers = []\n",
    "    start_pointer = 0\n",
    "    for bs_len_item in bs_len:\n",
    "        end_pointer = start_pointer + bs_size + bs_len_item - 1\n",
    "        pointer_list = list(range(start_pointer, end_pointer))\n",
    "        bs_pointers.append(pointer_list)\n",
    "        start_pointer = start_pointer + bs_len_item\n",
    "    return bs_pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_seq, bs_len = extract_modified_bs_sequence(sax_sequence)\n",
    "bs_point = generate_bs_pointers(bs_len, win_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get list of all BS subsequences with a fixed BS size\n",
    "\n",
    "**input:** bs_seq, bs_point and subseq_size\n",
    "\n",
    "**output:** subseq_bs_list and subseq_point_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bs_subsequences_list(bs_seq, bs_point, subseq_size):\n",
    "    # initialize lists to save the subsequences\n",
    "    subseq_bs_list = []\n",
    "    subseq_point_list = []\n",
    "    for i in range(len(bs_seq) - subseq_size + 1):\n",
    "        # extract the bs subsequence and append it to the list\n",
    "        subseq_bs = bs_seq[i:(i+subseq_size)]\n",
    "        subseq_bs_list.append(subseq_bs)\n",
    "        # extract the pointers of the bs subsequence and append it to the list\n",
    "        subseq_point = list(set(np.concatenate(bs_point[i:(i+subseq_size)])))\n",
    "        subseq_point_list.append(subseq_point)\n",
    "    return subseq_bs_list, subseq_point_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subseq_size = 3\n",
    "\n",
    "subseq_bs_list, subseq_point_list = get_bs_subsequences_list(bs_seq, bs_point, subseq_size)\n",
    "print(len(subseq_bs_list))\n",
    "subseq_bs_set = [list(item) for item in set(tuple(row) for row in subseq_bs_list)]\n",
    "print(len(subseq_bs_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extract all time series subsequences in a BS pattern\n",
    "\n",
    "**input:** ts, subseq_bs_list, subseq_len_list, subseq_point_list and pattern\n",
    "\n",
    "**output:** pattern_ts_list, pattern_len_listand  pattern_point_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_subsequences_in_pattern(ts, subseq_bs_list, subseq_point_list, pattern):\n",
    "    # initialize list to save the subsequences that bellong to the pattern\n",
    "    pattern_ts_list = []\n",
    "    pattern_pos_list = []\n",
    "    # for each bs subsequence:\n",
    "    for i in range(len(subseq_bs_list)):\n",
    "        # if the subsequence bellongs to the pattern:\n",
    "        if subseq_bs_list[i] == pattern:\n",
    "            # save the position of the subsequence in the list\n",
    "            pattern_pos_list.append(i)\n",
    "            # extract the initial ts data of that subsequence and append it to the list\n",
    "            pattern_ts = ts[subseq_point_list[i]]\n",
    "            pattern_ts_list.append(pattern_ts)\n",
    "    return pattern_ts_list, pattern_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = subseq_bs_list[2]\n",
    "pattern_ts_list, pattern_pos_list = get_all_subsequences_in_pattern(ts_1d, subseq_bs_list, subseq_point_list, pattern)\n",
    "print(pattern_ts_list)\n",
    "print(pattern_pos_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compute DTW distance matrix\n",
    "\n",
    "**input:** ts_list and R (max distance)\n",
    "\n",
    "**output:** dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dtw_dist_mat(ts_list, R=None):\n",
    "    dist_matrix_vec = dtw.distance_matrix(ts_list, parallel=True, max_dist=R)\n",
    "    dist_matrix = np.triu(dist_matrix_vec) + np.triu(dist_matrix_vec).T\n",
    "    np.fill_diagonal(dist_matrix, 0)\n",
    "    return dist_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat = compute_dtw_dist_mat(pattern_ts_list)\n",
    "dist_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Find center and final members of a pattern\n",
    "\n",
    "This step implements the distance constrain. And the overlapping contrain?\n",
    "\n",
    "**input:**\n",
    "\n",
    "**output:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index_of_pattern_center_and_members(dist_mat, subseq_point_list, pattern_pos_list, R):\n",
    "    \"\"\"Finds the index of the motif's center and members\"\"\"\n",
    "    pattern_point_list = [subseq_point_list[i] for i in pattern_pos_list]\n",
    "    count_members_list = count_members_in_pattern(dist_mat, pattern_point_list, R)\n",
    "    max_count = max(count_members_list)\n",
    "    sum_dist_list = []\n",
    "    for i in range(len(dist_mat)):\n",
    "        if count_members_list[i]==max_count:\n",
    "            row = dist_mat[i]\n",
    "            pruned_members_index = prune_pattern_members(row, pattern_point_list)\n",
    "            sum_dist = sum([row[i] for i in pruned_members_index])\n",
    "        else:\n",
    "            sum_dist = np.inf\n",
    "        sum_dist_list.append(sum_dist)\n",
    "    center_index = np.argmin(sum_dist_list)\n",
    "    mean_dist = sum_dist_list[center_index]/float(count_members_list[center_index])\n",
    "    center_row = dist_mat[center_index]\n",
    "    members_index = prune_pattern_members(center_row, pattern_point_list)\n",
    "    # extract the center and members position in the subseq list\n",
    "    center_pos = pattern_pos_list[center_index]\n",
    "    members_pos = [pattern_pos_list[i] for i in members_index]\n",
    "    return center_pos, members_pos, mean_dist\n",
    "\n",
    "\n",
    "def prune_pattern_members(dist_row, pattern_point_list):\n",
    "    members_in_radius_index = [index for index,value in enumerate(dist_row) if value < R]\n",
    "    dist_in_radius = [dist_row[i] for i in members_in_radius_index]\n",
    "    members_with_no_overlap_index = [members_in_radius_index[0]]\n",
    "    for i in range(1, len(members_in_radius_index)):\n",
    "        if lists_overlap(pattern_point_list[members_in_radius_index[i]],\n",
    "                         pattern_point_list[members_with_no_overlap_index[-1]]):\n",
    "            dist_in = dist_in_radius[members_with_no_overlap_index[-1]]\n",
    "            dist_out = dist_in_radius[members_in_radius_index[i]]\n",
    "            if dist_in > dist_out:\n",
    "                members_with_no_overlap_index = members_with_no_overlap_index[:-1]\n",
    "                members_with_no_overlap_index.append(members_in_radius_index[i])\n",
    "        else:\n",
    "            members_with_no_overlap_index.append(members_in_radius_index[i])\n",
    "    return members_with_no_overlap_index\n",
    "\n",
    "\n",
    "def lists_overlap(l1, l2):\n",
    "    intersection_set = set(l1).intersection(set(l2))\n",
    "    overlaping_test = (len(intersection_set) > 0)\n",
    "    return overlaping_test\n",
    "\n",
    "\n",
    "def count_overlaps(point_list):\n",
    "    overlap_count = 0\n",
    "    for i in range(len(point_list)-1):\n",
    "        if lists_overlap(point_list[i], point_list[i+1]):\n",
    "            overlap_count = overlap_count + 1\n",
    "    return overlap_count\n",
    "\n",
    "def count_members_in_pattern(dist_mat, pattern_point_list, R):\n",
    "    count_members_list = []\n",
    "    for dist_row in dist_mat:\n",
    "        members_point_list = [pattern_point_list[index] for index,value in enumerate(dist_row) if value < R]\n",
    "        count_members = len(members_point_list) - count_overlaps(members_point_list)\n",
    "        count_members_list.append(count_members)\n",
    "    return count_members_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 30\n",
    "center_pos, members_pos, mean_dist = find_index_of_pattern_center_and_members(dist_mat, subseq_point_list, pattern_pos_list, R)\n",
    "print(center_pos)\n",
    "print(members_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compute MDL\n",
    "\n",
    "**input:**\n",
    "\n",
    "**output:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def break_bs_len_seq(bs_len, break_points, subseq_size):\n",
    "    bs_len_break = []\n",
    "    if break_points[0] > 0:\n",
    "        first_seq = bs_len[0:break_points[0]]\n",
    "        bs_len_break.append(first_seq)\n",
    "    for i in range(len(break_points)-1):\n",
    "        pattern_seq = bs_len[break_points[i]:break_points[i]+subseq_size]\n",
    "        bs_len_break.append(pattern_seq)\n",
    "        next_seq = bs_len[break_points[i]+subseq_size:break_points[i+1]]\n",
    "        bs_len_break.append(next_seq)\n",
    "    final_pattern_seq = bs_len[break_points[-1]:break_points[-1]+subseq_size]\n",
    "    bs_len_break.append(final_pattern_seq)\n",
    "    if break_points[-1]+subseq_size < len(bs_len)-1:\n",
    "        final_seq = bs_len[break_points[-1]+subseq_size:]\n",
    "        bs_len_break.append(final_seq)\n",
    "    return bs_len_break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_segmentation_len_list = break_bs_len_seq(bs_len, members_pos, subseq_size)\n",
    "print([len(seq) for seq in bs_segmentation_len_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pattern_mdl(seg_len_list):\n",
    "    par_cost_list = []\n",
    "    data_cost_list = []\n",
    "    for seg in seg_len_list:\n",
    "        seg_len_sum = float(sum(seg))\n",
    "        seg_par_cost = math.log2(seg_len_sum)\n",
    "        par_cost_list.append(seg_par_cost)\n",
    "        seg_data_cost_list = [-l*math.log2(l/seg_len_sum) for l in seg]\n",
    "        seg_data_cost = sum(seg_data_cost_list)\n",
    "        data_cost_list.append(seg_data_cost)\n",
    "    par_cost = sum(par_cost_list)\n",
    "    data_cost = sum(data_cost_list)\n",
    "    seg_cost = len(seg_len_list)*math.log2(sum(np.concatenate(seg_len_list)))\n",
    "    mdl_cost = par_cost + data_cost + seg_cost\n",
    "    return mdl_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_pattern_mdl(bs_segmentation_len_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extact all motif candidates\n",
    "\n",
    "5. Find all the motif candidates:\n",
    "    1. Set the size of analysis window, W, to `T_min`.\n",
    "    2. Extract all modified BS subsequences under the analysis window, by sliding the window from left to right. Find some DL pattern from these subsequences, if any. If there exists no DL pattern found and the window is now at the end of the Modified BS sequence, go to step 6.\n",
    "    3. From the set of all pattern instances found in 5.B, establish the distance matrix for them (using DTW distance to calculate the distances between them). Call the procedure `Extract_Motif_Candidate` to find the motif candidate from the distance matrix, and calculate the MDL value of the candidate.\n",
    "    4. Add the motif candidate to the result list along with its MDL value.\n",
    "    5. Increase the size of the analysis window (i.e., Set W: = W + 1), go to 5.2\n",
    "6. From the result list, find the motif candidate with the smallest MDL value. The found motif will be the returned result\n",
    "\n",
    "**input:** ts, bs_seq, bs_point, R\n",
    "\n",
    "**output:** motif_mdl, motif_pointers, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_motif_candidates(ts, bs_seq, bs_len, bs_point, R):\n",
    "    # initialize the output lists\n",
    "    mdl_cost_list = []\n",
    "    motif_point_list = []\n",
    "    pattern_list = []\n",
    "    # initialize the size of the BS subsequences\n",
    "    subseq_size = 1\n",
    "    while True:\n",
    "        subseq_bs_list, subseq_point_list = get_bs_subsequences_list(bs_seq, bs_point, subseq_size)\n",
    "        subseq_bs_set = [list(item) for item in set(tuple(row) for row in subseq_bs_list)]\n",
    "        if len(subseq_bs_list)==len(subseq_bs_set):\n",
    "            break\n",
    "        for pattern in subseq_bs_set:\n",
    "            pattern_ts_list, pattern_pos_list = get_all_subsequences_in_pattern(ts, subseq_bs_list, subseq_point_list, pattern)\n",
    "            # if the pattern only has one subsequence, then it is not a motif\n",
    "            if len(pattern_pos_list) < 2:\n",
    "                continue\n",
    "            dist_mat = compute_dtw_dist_mat(pattern_ts_list)\n",
    "            # compute the center the the members of the motif candidate and\n",
    "            # return their position in the BS subsequence\n",
    "            center_pos, members_pos, mean_dist = find_index_of_pattern_center_and_members(dist_mat, subseq_point_list, pattern_pos_list, R)\n",
    "            # if the pattern only has one subsequence, then it is not a motif\n",
    "            if len(members_pos) < 2:\n",
    "                continue\n",
    "            # get the segmentation of the BS subseq fo lenghts, based on the motif (the motif segmentation)\n",
    "            bs_segmentation_len_list = break_bs_len_seq(bs_len, members_pos, subseq_size)\n",
    "            # Exclude empty lists (happens when there's overlapping patterns) --------------------------------------------- NEED TO CORRECT THIS!!!!\n",
    "            bs_segmentation_len_list = [item for item in bs_segmentation_len_list if len(item)>0]\n",
    "            # compute the MDL of the motif segmentation and append it to the list\n",
    "            mdl_cost = compute_pattern_mdl(bs_segmentation_len_list)\n",
    "            mdl_cost_list.append(mdl_cost)\n",
    "            # extract the motif pointers (i.e. indices of the ts where all the motif members are located)\n",
    "            # and append it to the list\n",
    "            motif_point = [subseq_point_list[i] for i in members_pos]\n",
    "            motif_point_list.append(motif_point)\n",
    "            # append the pattern to the pattern list\n",
    "            pattern_list.append(pattern)\n",
    "        print('motif candidates of size {} successfully extracted'.format(subseq_size))\n",
    "        # go to the next subsequence size\n",
    "        subseq_size = subseq_size + 1\n",
    "    return mdl_cost_list, motif_point_list, pattern_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "R = 30\n",
    "mdl_cost_list, motif_point_list, pattern_list = find_all_motif_candidates(ts_1d, bs_seq, bs_len, bs_point, R)\n",
    "\n",
    "pickle.dump(ts_1d, open(\"ts_1d.p\", \"wb\"))\n",
    "pickle.dump(mdl_cost_list, open(\"mdl_cost.p\", \"wb\"))\n",
    "pickle.dump(motif_point_list, open(\"motif_point.p\", \"wb\"))\n",
    "pickle.dump(pattern_list, open(\"patterns.p\", \"wb\"))\n",
    "\n",
    "print(\"All motif candidates algorithm run in {} minutes\".format(round((time.time() - start_time)/60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(mdl_cost_list).describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
